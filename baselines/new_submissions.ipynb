{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "import csv\n",
    "#from models import *\n",
    "from models_full_pretrained_train import *\n",
    "from feature_extraction import train_test_features, save\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "import os\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "#             print(y_pred)\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, y, X_test, max_features, W] = cPickle.load(open(\"embedding_hashtag_split/features_pretrained_full_no_old_clean.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1046: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1153: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 200)           78311400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 31, 32)            32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 78,417,881\n",
      "Trainable params: 78,417,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = load_model('embedding_hashtag_split/model3_full_dataset_1_epochs_no_old_clean.plk')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9920/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predicted_labels = model3.predict_proba(X_test)\n",
    "predicted_labels[predicted_labels >= 0.5] = 1\n",
    "predicted_labels[predicted_labels < 0.5] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "#             print(y_pred)\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})\n",
    "\n",
    "\n",
    "create_csv_submission(np.arange(1, X_test.shape[0]+1), predicted_labels, 'model3_full_dataset_1_epochs_no_old_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 200)           78311400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 31, 32)            32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 78,417,881\n",
      "Trainable params: 78,417,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = load_model('embedding_hashtag_split/model3_full_dataset_2_epochs_no_old_clean.plk')\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predicted_labels = model3.predict_proba(X_test)\n",
    "predicted_labels[predicted_labels >= 0.5] = 1\n",
    "predicted_labels[predicted_labels < 0.5] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(np.arange(1, X_test.shape[0]+1), predicted_labels, 'model3_full_dataset_2_epochs_no_old_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 200)           78311400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 31, 32)            32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 15, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 78,417,881\n",
      "Trainable params: 78,417,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      " 9792/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model3 = load_model('embedding_hashtag_split/model3_full_dataset_3_epochs_no_old_clean.plk')\n",
    "model3.summary()\n",
    "\n",
    "\n",
    "predicted_labels = model3.predict_proba(X_test)\n",
    "predicted_labels[predicted_labels >= 0.5] = 1\n",
    "predicted_labels[predicted_labels < 0.5] = -1\n",
    "\n",
    "create_csv_submission(np.arange(1, X_test.shape[0]+1), predicted_labels, 'model3_full_dataset_3_epochs_no_old_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train, y, X_test, max_features, W] = cPickle.load(open(\"embedding_hashtag_split/features_pretrained_full.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 200)           78329600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 26, 32)            32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 78,436,849\n",
      "Trainable params: 78,436,465\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 2s     \n"
     ]
    }
   ],
   "source": [
    "model5 = load_model('embedding_hashtag_split/model5_full_dataset_1_epochs.plk')\n",
    "model5.summary()\n",
    "\n",
    "\n",
    "predicted_labels = model5.predict_proba(X_test)\n",
    "predicted_labels[predicted_labels >= 0.5] = 1\n",
    "predicted_labels[predicted_labels < 0.5] = -1\n",
    "\n",
    "create_csv_submission(np.arange(1, X_test.shape[0]+1), predicted_labels, 'model5_full_dataset_1_epochs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 200)           78329600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 26, 32)            32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 78,436,849\n",
      "Trainable params: 78,436,465\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "model5 = load_model('embedding_hashtag_split/model5_full_dataset_2_epochs.plk')\n",
    "model5.summary()\n",
    "\n",
    "\n",
    "predicted_labels = model5.predict_proba(X_test)\n",
    "predicted_labels[predicted_labels >= 0.5] = 1\n",
    "predicted_labels[predicted_labels < 0.5] = -1\n",
    "\n",
    "create_csv_submission(np.arange(1, X_test.shape[0]+1), predicted_labels, 'model5_full_dataset_2_epochs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 200)           78329600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 26, 32)            32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 78,436,849\n",
      "Trainable params: 78,436,465\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      " 9920/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model5 = load_model('embedding_hashtag_split/model5_full_dataset_3_epochs.plk')\n",
    "model5.summary()\n",
    "\n",
    "\n",
    "predicted_labels = model5.predict_proba(X_test)\n",
    "predicted_labels[predicted_labels >= 0.5] = 1\n",
    "predicted_labels[predicted_labels < 0.5] = -1\n",
    "\n",
    "create_csv_submission(np.arange(1, X_test.shape[0]+1), predicted_labels, 'model5_full_dataset_3_epochs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
